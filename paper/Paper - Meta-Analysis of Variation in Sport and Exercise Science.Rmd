---
title: "Meta-Analysis of Variation in Sport and Exercise Science"
subtitle: "Examples of Application Within Resistance Training Research"
author: 
  - James Steele
  - James Fisher
  - Dave Smith
  - Andrew Vigotsky
  - Brad Schoenfeld
  - Yefeng Yang
  - Shinichi Nakagawa
date: "2022-08-04"
abstract: |
  TO COMPLETE.
output: bookdown::pdf_document2
bibliography: references.bib
toc: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
options(knitr.kable.NA = '')
```
```{r, message=FALSE, warning=FALSE, echo=FALSE, cache=TRUE}
# Load relevant packages
library(here)
library(kableExtra)
```
```{r, message=FALSE,warning=FALSE,echo=FALSE}
# load the raw data to the environment
Data <- read.csv(here::here("data","Polito et al. RT Extracted Data.csv"), na.strings=c(""," ","NA"))

# load the summary dataframes to the environment
load(here("models/SMD_SDir_logVR"))
load(here("models/mods_SMD_logCVR"))


```
# Introduction
Though the quantitative synthesis of results across studies has existed since the 17th century [@plackett_studies_1958], the modern day term "meta-analysis" as it is now referred to was coined by Gene Glass in [-@glass_primary_1976]. Since that time use of meta-analysis as a tool for the synthesis of research in sport and exercise science has increased considerably [@hagger_meta-analysis_2022]. One area of sport and exercise science which has comprised a considerable proportion of that growth appears to have been in the study of resistance training (RT; figure \@ref(fig:trend-plot)). Given such growth, throughout the paper we use RT studies as a hopefully familiar example for sport and exercise science researchers.
```{r trend-plot, echo=FALSE,fig.height=4, fig.width=6, fig.cap="Trends in meta-analyses published in sport and exercise science since 1976"}

load(here("plots/trends_plot"))
trends_plot

```
As with many other fields [@nakagawa_meta-analysis_2015; @usui_meta-analysis_2021; @mills_detecting_2021] likely the most familiar aim with the use of meta-analysis, and indeed primary empirical research too, in sport and exercise science is to make comparisons between the means of measurements taken across different categorical grouping variables; for example, the comparison of an intervention group and a control group, the comparison of one intervention group to another, or comparison between non-manipulated categories such as biological sex. Indeed, a recent umbrella review [@bernardez-vazquez_resistance_2022] of meta-analyses in RT identified 14 studies examining the manipulation of RT intervention variables (i.e., the comparison of one intervention to another whereby a variable in the intervention was manipulated) on hypertrophy outcomes all of which focused on the comparison of mean changes between different intervention groups. 
 
Most commonly a magnitude based[^1] effect size statistic [@caldwell_case_2020], the standardised mean difference (SMD), is used to compare means between groups or conditions. This is usually Cohen's *d* [@cohen_statistical_1988], or it's bias-corrected metric referred to as Hedges' *g* [@hedges_statistical_2014; @borenstein_introduction_2021; @nakagawa_effect_2007] [^2]. The SMD, and its sampling variance, $s^2_{SMD}$ are given by:

\begin{equation}
SMD=\frac{\overline{x}_E - \overline{x}_C}{s_{pooled}}J
(\#eq:SMD-eq)
\end{equation}

\begin{equation}
J=1-\frac{3}{4(n_{C}+n_{E})-2)-1}
(\#eq:biasJ-eq)
\end{equation}

\begin{equation}
s_{pooled}=\sqrt{\frac{(n_{C}-1)s^2_{C}+(n_{E}-1)s^2_{E}}{n_{C}+n_{E}-2}}
(\#eq:s-pooled-eq)
\end{equation}

\begin{equation}
s^2_{SMD}=\frac{n_{C}+n_{E}}{n_{C}n_{E}}+\frac{SMD^2}{2(n_{E}+n_{C})}
(\#eq:SMDvar-eq)
\end{equation}

where $\overline{x}_C$ and $\overline{x}_E$ are the sample means of the control group (C) and experimental (E) or intervention group respectively, $s_C$ and $s_E$ are the standard deviations of the two groups, $n_C$ and $n_E$ are the sample sizes of the two groups, and $J$ is a bias correction for small sample sizes.

The natural logarithm of the ratio of two means ($\textrm{ln}RR$) is also another effect size statistic that can be used [@curtis_meta-analysis_1998; @hedges_meta-analysis_1999; @lajeunesse_bias_2015]. The lnRR, and its sampling variance, $s^2_{\textrm{ln}RR}$ are given by:

\begin{equation}
\textrm{ln}RR=\textrm{ln}\frac{\overline{x}_E}{\overline{x}_C}
(\#eq:lnRR-eq)
\end{equation}

\begin{equation}
s^2_{\textrm{ln}RR}=\frac{s^2_{C}}{n_{C}\overline{x}^2_{C}}+\frac{s^2_{E}}{n_{E}\overline{x}^2_{E}}
(\#eq:lnRRvar-eq)
\end{equation}

Due to its calculation the SMD is affected not only by the difference in means of the two groups, but is also affected by the standard deviations of both groups due to the standardisation of the effect size by $s_{pooled}$. Contrastingly, the $\textrm{ln}RR$ is uninfluenced by the standard deviations in either groups (see equation \@ref(eq:lnRR-eq)), which only affects the sampling variance (see equation \@ref(eq:lnRRvar-eq)). Despite this, use of $\textrm{ln}RR$ has been limited in previous meta-analyses in sport and exercise science [@deb_quantifying_2018] and to our knowledge only one meta-analysis in RT has used this effect size (Swinton et al., in press).

Though the focus in sport and exercise science among other fields has been in estimating the average effects of interventions for both primary research and synthesis through meta-analysis, the field has been aware for some time that responses to certain interventions do vary potentially on a subgroup or even individual basis. The increased interested in *precision* or *personalised* approaches to exercise prescription has resulted in a number of opinion and methodological review articles discussing statistical approaches to understanding interindividual response heterogeneity to exercise interventions [@hecksteden_individual_2015; @atkinson_true_2015; @atkinson_issues_2019; @ross_precision_2019; @swinton_statistical_2018; @hopkins_individual_2015; @kelley_precision_2022; @hrubeniuk_directions_2022; @pickering_non-responders_2019]. However, despite the availability of approaches to compare variances between groups, in sports and exercise science this is rarely explored in primary research [@bonafiglia_interindividual_2022] and, though there has been increased interest in recent years, few meta-analyses in sport and exercise include both comparisons of means and variances or explicitly aim to investigate the latter [@kelley_are_2022; @kelley_are_2020; @esteves_individual_2021; @bonafiglia_interindividual_2022; @steele_slow_2021; @fisher_role_2022]. Examination of interindividual heterogeneity in response to interventions presents considerable value to researchers and practitioners in sport and exercise science; interventions with low interindividual variation are likely to be widely generalisable, whilst an intervention with high interindividual variation is likely to have effects that are either subgroup or individual specific. The former kind of intervention might be widely applicable across individuals, whilst the latter kind of intervention requires specific research to tease apart subgroup- or participant-by-intervention interactions to enable successful practical application.

Comparison of heterogeneity in responses such as post-scores or change scores to interventions are however not the only possible use of statistical methods for comparing variances. For example, in other fields such as ecology there have been calls to shift focus onto the exploration of dispersion of traits between groups in non-experimental or interventional designs [@nakagawa_mean_2012]. Some recent examples from sport and exercise science, and RT in particular, include primary research exploring between participant acute response variation for the purposes of identifying methods[^3] to reduce RT stimulus heterogeneity [@exner_does_2022] as well as meta-analysis exploring between participant heterogeneity of accuracy in predicting proximity to task failure during RT [@halperin_accuracy_2022].

Given the value of embracing and exploring variation alongside mean effects in sport and exercise science, yet the lack of application in research synthesis by way of meta-analysis, we present and discuss effect size approaches and models for meta-analysis of variation. We provide examples of the approaches presented using data from RT studies included in a recent meta-analysis published in the *Journal of Sport Sciences* [@polito_moderators_2021].

# Effect size statistics for meta-analytic comparisons of variation
Until recent years there has been a dearth of effect size statistics available for the examination of variation in a meta-analytic framework. However, several have been proposed that we now describe: the standard deviation for individual responses ($SD_{ir}$; @hopkins_individual_2015; @atkinson_true_2015; @atkinson_issues_2019), the log ratio of standard deviations ($\textrm{ln}VR$; termed the "variability ratio"; @hedges_sex_1995), and the log ratio of coefficient of variation ($\textrm{ln}CVR$; termed the "coefficient of variation ratio"; @nakagawa_meta-analysis_2015).

## Standard deviation for individual responses ($SD_{ir}$)
In the context of *precision* or *personalised* approaches to exercise prescription comparison of variation between two groups, control (C) and intervention (E), the $SD_{ir}$ has been proposed as an approach to determining the extent to which individual responses manifest [@hopkins_individual_2015; @atkinson_true_2015; @atkinson_issues_2019]. The standard deviation of changes scores (post-intervention scores minus pre-intervention scores) within the intervention group reflects the gross combination of a number of sources of variation including participant-by-intervention interactions (i.e., actual individual responsiveness or 'trainability'), within-participant variability in intervention response (i.e., variability in response to the same intervention administered to the same participant), and random error (i.e., from pre and post measurements; @hecksteden_individual_2015). The standard deviation of change scores from the control group (assuming it is a non-intervention control group and not something like a 'usual-care' group) by contrast only reflects random error [@hecksteden_individual_2015]. As such, the difference in these standard deviations can be used to determine the extent to which additional variation has been introduced by the intervention that might reflect individual responses. The $SD_{ir}$, and its sampling variance, $s^2_{SD_{ir}}$ are given by:

\begin{equation}
SD_{ir}=\sqrt{s^2_{E} - s^2_{C}}
(\#eq:SDir-eq)
\end{equation}

\begin{equation}
s^2_{SD_{ir}}=2(\frac{s^4_{E}}{n_{E}-1}+\frac{s^4_{C}}{n_{C}-1})
(\#eq:sdIRvar-eq)
\end{equation}

Thus, the $SD_{ir}$ reflects a comparison of the absolute variance in change scores between C and E. Whilst the $SD_{ir}$ has been proposed and used primarily in the context of individual response variation to interventions, it should be noted that this kind of absolute comparison of variance between groups or conditions is not limited to such applications.

## Log ratio of standard deviations ($\textrm{ln}VR$)
A similar effect size statistic for the comparison of absolute variance between groups, and one which has had wide applications in more than just intervention response variability within fields like ecology and evolution, is the $\textrm{ln}VR$ [@nakagawa_meta-analysis_2015]. An unbiased estimator of the natural logarithm of a population standard deviation ($\textrm{ln}\sigma$), and its sampling variance, $s^2_{\textrm{ln}\sigma}$ is given by: 

\begin{equation}
\textrm{ln}\hat\sigma=\textrm{ln}s+\frac{1}{2(n-1)}
(\#eq:lnsigma-eq)
\end{equation}

\begin{equation}
s^2_{\textrm{ln}\hat\sigma}=\frac{1}{2(n-1)}
(\#eq:lnsigmavar-eq)
\end{equation}

where $\textrm{ln}\hat\sigma$ is an estimate of $\textrm{ln}\sigma$, and it is assumed with sufficiently large sample size and value of $\sigma$ that $\textrm{ln}\sigma$ is normally distributed with variance $s^2_{\textrm{ln}\sigma}$. Given equations \@ref(eq:lnsigma-eq) and \@ref(eq:lnsigmavar-eq), the logarithm of the ratio of standard deviations of two groups, such as a control (C) and intervention (E), the $\textrm{ln}VR$, and its sampling variance, $s^2_{\textrm{ln}VR}$ is given by: 

\begin{equation}
\textrm{ln}VR=\textrm{ln}(\frac{s_{E}}{s_{C}})+\frac{1}{2(n_{E}-1)}-\frac{1}{2(n_{C}-1)}
(\#eq:lnVR-eq)
\end{equation}

\begin{equation}
s^2_{\textrm{ln}VR}=\frac{1}{2(n_{E}-1)}+\frac{1}{2(n_{C}-1)}
(\#eq:lnVRvar-eq)
\end{equation}

However, due to both $SD_{ir}$ and $\textrm{ln}VR$ being comparisons of absolute variance, they may find limited applicability where the mean of one group is larger than the comparison group (e.g., when $\overline{x}_E$ is larger than $\overline{x}_C$). In this case it is likely that the standard deviation will be larger in the group with the larger mean (e.g., $s_{E}$ is larger than $s_{C}$). This mean-variance relationship is common for many variables and datasets[^4] and we will provide examples of this below. They also assume constant measurement error over the range of values for the mean which can impact their utility for examining response variation [@tenan_comment_2020].

## Log ratio of coefficient of variation ($\textrm{ln}CVR$)
The coefficient of variation is the ratio of the standard deviation to the mean; therefore, comparison of the coefficient of variation between groups will identify whether standard deviations differ more, or less, than would be predicted by their difference in means where a mean-variance relationship is present. The natural logarithm of the ratio between the coefficients of variation from two groups, the $\textrm{ln}CVR$ is thus a more generally applicable effect size statistic for examining variability between groups. Considering equations \@ref(eq:lnRR-eq) and \@ref(eq:lnVR-eq), the $\textrm{ln}CVR$ is given by:

\begin{equation}
\textrm{ln}CVR=\textrm{ln}(\frac{CV_{E}}{CV_{C}})+\frac{1}{2(n_{E}-1)}-\frac{1}{2(n_{C}-1)}
(\#eq:lnCVR-eq)
\end{equation}

where $CV_{E}$ and $CV_{C}$ are ${s_{E}}/{\overline{x}_{E}}$ and ${s_{C}}/{\overline{x}_{C}}$ respectively. Nakagawa et al. [-@nakagawa_meta-analysis_2015] derived the sampling variance, $s^2_{\textrm{ln}CVR}$, as:

\begin{equation}
\begin{split}
s^2_{\textrm{ln}CVR}=\frac{s^2_{C}}{n_{C}\overline{x}_{C}}+\frac{1}{2(n_{C}-1)}-2\rho_{\textrm{ln}\overline{x}_{C},\textrm{ln}{s}_{C}}\sqrt{\frac{s^2_{C}}{n_{C}\overline{x}_{C}}+\frac{1}{2(n_{C}-1)}} \\
+ \frac{s^2_{E}}{n_{E}\overline{x}_{E}}+\frac{1}{2(n_{E}-1)}-2\rho_{\textrm{ln}\overline{x}_{E},\textrm{ln}{s}_{E}}\sqrt{\frac{s^2_{E}}{n_{E}\overline{x}_{E}}+\frac{1}{2(n_{E}-1)}}
\end{split}
(\#eq:lnCVRvar-eq)
\end{equation}

where $\rho_{\textrm{ln}\overline{x}_{C},\textrm{ln}{s}_{C}}$ and $\rho_{\textrm{ln}\overline{x}_{E},\textrm{ln}{s}_{E}}$ are the correlatios between the means and the standard deviation in the C and E groups respectively on the log scale across studies.

# Examples using resistance training studies
As noted, the examples presented used data from RT studies included in a recent meta-analysis published in the *Journal of Sport Sciences* [@polito_moderators_2021]. Here we have used their list of included studies and re-extracted data from 111 of these[^5]. All analysis examples were performed in using R (version 4.2.1, "Funny-Looking Kid", The R Foundation for Statistical Computing, 2022) using the **metafor** package [@viechtbauer_conducting_2010]. The extracted dataset, analysis scripts, models, data summaries, and supplementary materials are all available on the Open Science Framework (https://osf.io/2h9ma/).

```{r sample-size-tab, message=FALSE, warning=FALSE, echo=FALSE}

load(here("models/sample_sizes"))

knitr::kable(
  sample_sizes,
  caption = 'Sample sizes for resistance training and non training control groups for dataset.'
  ) %>%
  pack_rows("RT", 1, 4) %>%
  pack_rows("CON", 5, 8) %>%
  footnote(general = c("RT = resistance training", "CON = non-training control")
           ) %>%
  row_spec(0, bold = TRUE) %>%
  kable_classic(full_width = FALSE) 


```

Polito et al. [-@polito_moderators_2021] conducted a systematic review and meta-analysis of randomised trials including a RT intervention where a non-training control comparison group was included. Their analysis focused upon the SMD between the RT interventions and control groups from the studies included, with both overall effect estimate and moderator analyses (i.e., meta-regressions) were performed. Given that Polito et al. [-@polito_moderators_2021] included only studies with non-training control groups, their study selection offers a unqiue context to examine variation of interindividual responses specifically by means of comparing the variances in change scores between the RT intervention and control groups. Table \@ref(tab:sample-size-tab) shows the total sample size, along with the median and range by group, across the included studies. Table \@ref(tab:summary-characteristics-tab) shows the study and participant characteristics.

```{r summary-characteristics-tab, message=FALSE, warning=FALSE, echo=FALSE}

load(here("models/summary_table"))

knitr::kable(
  summary_table,
  caption = 'Summary of study and participant characteristics.',
  align = c("l","c") 
  ) %>%
  pack_rows("Training Status",6, 7, bold = FALSE) %>%
  pack_rows("Sample Type", 8, 9, bold = FALSE) %>%
  pack_rows("RT + Adjuvant Intervention?", 10, 11, bold = FALSE) %>%
  pack_rows("Task Failure?", 18, 19, bold = FALSE) %>%
  footnote(general = c("RT = resistance training; ", "Continuous variables are median (IQR); ", "Categorical variables are count (%); ", "Not all studies reported full descriptive data (see dataset; https://osf.io/kg2z4)")
           ) %>%
  row_spec(0, bold = TRUE) %>%
  kable_classic(full_width = FALSE) %>%
    kable_styling()

```

## Detecting the presence of interindividual response variation to resistance training intervention
First we conduct a traditional SMD based effect size meta-analysis to explore the effects of RT compared to control for strength outcomes and hypertrophy (i.e., muscle mass/size) outcomes. Polito et al. [-@polito_moderators_2021] originally used a normal random-effects meta-analysis, however the data we extracted were hierarchical in nature (multiple effects within groups within studies) and so a multilevel mixed-effects meta-analysis model with cluster-robust variance estimation was used with random intercepts for study and group[^6]. We then fit the same model for the $SD_{ir}$ and $\textrm{ln}VR$ effect sizes for change scores (i.e., post-intervention minus pre-intervention scores) in order to explore how absolute variance in in responses differed between RT interventions and controls. A positive SMD would indicate that RT interventions increase outcomes compared to controls, whilst a positive $SD_{ir}$ and $\textrm{ln}VR$ would indicate that the introduction of the RT intervention increased variation in responses compared to controls (i.e., suggests the presence of interindividual response variation). 

```{r forest-plot, message=FALSE, warning=FALSE, echo=FALSE, fig.height=10, fig.width=10, fig.cap="Caterpillar plots of SMD effect sizes for strength (A) and hypertrophy (B) outcomes"}

# "Caterpillar plots of SMD effect sizes for strength and hypertrophy outcomes. Note, each estimate and 95% confidence interval is a single observed effect size within each group within each study, the diamond reflects the model overall estimate and 95% confidence interval, and the horizontal line with vertical bars at the end reflect the 95% prediction interval"

load(here("plots/forest_strength"))
load(here("plots/forest_hypertrophy"))
library(patchwork)
(forest_strength / forest_hypertrophy) +
  plot_annotation(tag_levels = "A")

```

The pattern of results from our models examining SMDs (figure \@ref(fig:forest-plot)) were similar to those reported by Polito et al. [-@polito_moderators_2021] albeit with slightly lower estimates for both outcome types; this possibly being due to our use of a multilevel mixed-effects meta-analysis model which allowed for each effect size included to be more appropriately weighted. As might be expected, in comparison to non-training controls the RT interventions produced increases in strength (SMD = `r SMD_SDir_logVR$Estimate[1]` [95%CI: `r SMD_SDir_logVR$Lower[1]` to `r SMD_SDir_logVR$Upper[1]`]; $I^2_{study}$ = `r SMD_SDir_logVR$I2.study[1]`, $I^2_{group}$ = `r SMD_SDir_logVR$I2.group[1]`) and hypertrophy outcomes (SMD = `r SMD_SDir_logVR$Estimate[4]` [95%CI: `r SMD_SDir_logVR$Lower[4]` to `r SMD_SDir_logVR$Upper[4]`]; $I^2_{study}$ = `r SMD_SDir_logVR$I2.study[4]`, $I^2_{group}$ = `r SMD_SDir_logVR$I2.group[4]`). Confidence intervals were precise for both outcomes, though prediction intervals for SMD estimates (see figure \@ref(fig:forest-plot)) were fairly wide and relative heterogeneity was fairly high coming mostly from between study variance[^7].

In addition to the SMD results, both the $SD_{ir}$ and $\textrm{ln}VR$ were also positive for both strength ($SD_{ir}$ = `r SMD_SDir_logVR$Estimate[2]` [95%CI: `r SMD_SDir_logVR$Lower[2]` to `r SMD_SDir_logVR$Upper[2]`]; $I^2_{study}$ = `r SMD_SDir_logVR$I2.study[2]`, $I^2_{group}$ = `r SMD_SDir_logVR$I2.group[2]`; $\textrm{ln}VR$ = `r SMD_SDir_logVR$Estimate[3]` [95%CI: `r SMD_SDir_logVR$Lower[3]` to `r SMD_SDir_logVR$Upper[3]`]; $I^2_{study}$ = `r SMD_SDir_logVR$I2.study[3]`, $I^2_{group}$ = `r SMD_SDir_logVR$I2.group[3]`) and hypertrophy outcomes ($SD_{ir}$ = `r SMD_SDir_logVR$Estimate[5]` [95%CI: `r SMD_SDir_logVR$Lower[5]` to `r SMD_SDir_logVR$Upper[5]`]; $I^2_{study}$ = `r SMD_SDir_logVR$I2.study[5]`, $I^2_{group}$ = `r SMD_SDir_logVR$I2.group[5]`; $\textrm{ln}VR$ = `r SMD_SDir_logVR$Estimate[6]` [95%CI: `r SMD_SDir_logVR$Lower[6]` to `r SMD_SDir_logVR$Upper[6]`]; $I^2_{study}$ = `r SMD_SDir_logVR$I2.study[6]`, $I^2_{group}$ = `r SMD_SDir_logVR$I2.group[6]`) suggesting that exposure to the RT interventions may have introduced additional variance over and above random error, potentially suggesting the presence of of interindividual response variation. This might support the previous perspectives [@carpinelli_interindividual_2017] that the considerable variation in responses to RT interventions typically observed are due to 'true' interindividual response variation over and above the random error that occurs from pre- and post-intervention measurements (i.e., the variation is *detectable* apart from the random error). However, as noted both the $SD_{ir}$ and $\textrm{ln}VR$ assume constant variance over values of the mean. As we have seen from the SMD analysis RT interventions increase mean scores. Thus, if there is a mean-variance relationship in the data an increase in the mean alone may be fully responsible for any apparent increase in variation. As such, we cannot rely solely on absolute comparisons of variance such as the $SD_{ir}$ and $\textrm{ln}VR$ to determine whether interindividual response variation is actually present. The $\textrm{ln}CVR$ can be used to overcome this issue, and below we re-analyse this dataset using this effect size statistic. First though, we present data demonstrating the ubiquity of the mean-variance relationship in typical RT study outcome measures and introduce a model that can also be used to overcome some possible limitations with the $\textrm{ln}CVR$.


## Mean-variance relationships in muscular strength and hypertrophy
With meta-analytic models of variation we are not limited to solely exploring variation in responses to interventions. We can explore the relationships between variance in a number of outcomes and the impact of certain predictors on this. For example, as noted one possible predictor of variance is the mean itself. As such, we can model variance as the response itself. The standard deviation is however bounded at zero and so in many cases it may not conform to assumptions of normality. Therefore, we instead can use $\textrm{ln}\hat\sigma$ which is unbounded. In the following example we explore the mean-variance relationship in the pre-intervention scores for outcomes in the data set from Polito et al. [-@polito_moderators_2021] using a multilevel mixed-effects model.


```{r mean-variance-pre-plot, message=FALSE, warning=FALSE, echo=FALSE,fig.height=8, fig.width=10, fig.cap="Scatter plots of raw mean and standard deviation of pre-intervention scores for (A) strength outcomes and (B) hypertrophy outcomes, and of the log mean and log standard deviation of pre-intervention scores for (C) strength outcomes and (D) hypertrophy outcomes"}

load(here("plots/mean_variance_pre_plots"))

mean_variance_pre_plots

```

As can be seen in figure \@ref(fig:mean-variance-pre-plot)(A) & (B), there is considerable heteroskedasticity in the relationship between the raw mean ($\overline{x}$) and standard deviation ($s$). This is similar to what is known as Taylor's law in ecology, or the power law; in essence, an empirically derived relationship stating that the variance is a power function of the mean in many biological and physical systems [@taylor_aggregation_1961]. 

\begin{equation}
s^2=a\overline{x}^b
(\#eq:taylors-eq)
\end{equation}

where $a$ and $b$ are some constants. When this relationship (equation \@ref(eq:taylors-eq)) holds, under most circumstances the standard deviation is not proportional to the mean. However, when the mean and standard deviation are transformed to the log scale this relationship becomes linear:

\begin{equation}
2\textrm{ln}s=\textrm{ln}a+b\textrm{ln}\overline{x}
(\#eq:taylorsln-eq)
\end{equation}

Figure \@ref(fig:mean-variance-pre-plot)(C) & (D) shows that the relationship between the mean and variance on the log scale better meets the assumption of normality. Given these the observations we have for $\textrm{ln}\hat\sigma$ and $\textrm{ln}\overline{x}$ come from outcomes over multiple groups and studies we can also estimate this relationship using the following model:

\begin{equation}
\textrm{ln}\hat\sigma_{ij}=(\beta_{0}+\tau_{(1)i}+\tau_{(2)j})+\beta_{1}\textrm{ln}\overline{x}_{ij}+\epsilon_{ij}+m_{ij} 
(\#eq:lnm-lns-model-eq)
\end{equation}

where $\textrm{ln}\hat\sigma_{ij}$ is the effect size, as in equation \@ref(eq:lnsigma-eq), from the $j\textrm{th}$ group ($j = 1,2,\cdots,N_{j}$; where $N_{j}$ is the number of groups) in the $i\textrm{th}$ study ($i = 1,2,\cdots,N_{i}$; where $N_{i}$ is the number of studies), $\textrm{ln}\overline{x}_{ij}$ is the mean estimate for each effect size, $\beta_{0}$ is the intercept, $\beta_{1}$ is the slope or regression coefficient for $\textrm{ln}\overline{x}$, $\tau_{i}$ is the deviation from $\beta_{0}$ for the $i\textrm{th}$ study and $\tau_{j}$ is the deviation for the $j\textrm{th}$ group, and $\epsilon_{ij}$ is the residual for each effect size which is normally distributed with $\sigma^2_{\epsilon}$, and $m_{ij}$ is the sampling error for each effect size normally distributed with $\sigma^2_{\textrm{ln}\hat\sigma_{ij}}$. Additional predictor terms could be added to this model; for example, we could model a categorical variable for the outcome type and include $(\beta_{2} + \varphi_{i} + \varphi_{j})Outcome$ in the model with $Outcome$ as a dummy coded variable for the outcome type (i.e., hypertrophy = 0, and strength = 1), where $\beta_{2}$ is the slope or regression coefficient for $Outcome$ (most intuitively thought of as the difference between the two outcome groups), and $\varphi_{i}$ is the deviation (random slope) from $\beta_{2}$ for the $i\textrm{th}$ study and $\varphi_{j}$ is the deviation for the $j\textrm{th}$ group. In this case $\tau_{i}$ and $\varphi_{i}$, and $\tau_{j}$ and $\varphi_{j}$ are assumed to have multivariate normal distributions with the following variance-covariance structure: 

\begin{equation}
\binom{\tau}{\varphi}=(\binom{0}{0},
\left(\begin{array}{cc} 
\sigma^2_{\tau} & \rho\sigma_{\tau}\sigma_{\varphi}\\
\rho\sigma_{\tau}\sigma_{\varphi} & \sigma^2_{\varphi}
\end{array}\right))
(\#eq:lnCVR-model-varcov-eq)
\end{equation}


Figure \@ref(fig:model-mean-variance-pre-plot) shows this model fit visually. Both strength and hypertrophy outcomes show strong linearity between the mean and standard deviation on the log scale, though there is a small difference in intercepts between the two outcome types suggesting a slight systematically greater degree of variance in strength measures compared to hypertrophy for a given mean score. 

```{r model-mean-variance-pre-plot, message=FALSE, warning=FALSE, echo=FALSE,fig.height=4, fig.width=6, fig.cap="Meta-analytic scatter plot of the log mean and log standard deviation of pre-intervention scores"}

# "Meta-analytic scatter plot of the log mean and log standard deviation of pre-intervention scores. Note, fitted lines are the regression slopes for strength and hypertophy outcomes each with their 95% confidence interval band."

load(here("plots/model_mean_variance_pre_plots"))

model_mean_variance_pre_plots

```

The presence of Taylor's law type relationships should be examined in datasets prior to deciding on which variance effect size statistic should be employed. Returning to the context of interindividual response variation to interventions, the presence of a mean-variance relationship in the data would imply that we cannot rely on absolute comparisons of variance (i.e., $SD_{ir}$ or $\textrm{ln}VR$) to determine whether interindividual response variation is actually present. So we should also explore this for the change-scores in the RT and control groups and determing the appropriate effects to explore.

## Reanalysis of interindividual response variation using $lnCVR$ and the random slope mixed effects model
As can be seen in figure \@ref(fig:mean-variance-delta-plot) there is a mean-variance relationship in the change score data whereby an increase in the mean alone (i.e., greater mean change score in the intervention compared to the control) may be fully responsible for any apparent increase in variation. As such, we cannot rely solely on absolute comparisons of variance such as the $SD_{ir}$ and $\textrm{ln}VR$ to determine whether interindividual response variation is actually present. 

```{r mean-variance-delta-plot, message=FALSE, warning=FALSE, echo=FALSE,fig.height=8, fig.width=10, fig.cap="Scatter plots of raw mean and standard deviation of change scores for (A) strength outcomes and (B) hypertrophy outcomes, and of the log mean and log standard deviation of change scores for (C) strength outcomes and (D) hypertrophy outcomes"}

load(here("plots/mean_variance_delta_plots"))

mean_variance_delta_plots

```

The $\textrm{ln}CVR$ can be used to overcome this issue though. Fitting the same multilevel mixed-effects meta-analysis model with cluster-robust variance estimation was used with random intercepts for study and group and before using the $\textrm{ln}CVR$ as the response variable leads to different conclusions compared to absolute variance comparisons. The introduction of an RT intervention actually *reduces* the relative variation seen in change scores for strength ($\textrm{ln}CVR$ = `r mods_SMD_logCVR$Estimate[28]` [95%CI: `r mods_SMD_logCVR$Lower[28]` to `r mods_SMD_logCVR$Upper[28]`]; $I^2_{study}$ = `r mods_SMD_logCVR$I2.study[28]`, $I^2_{group}$ = `r mods_SMD_logCVR$I2.group[28]`) and hypertrophy ($\textrm{ln}CVR$ = `r mods_SMD_logCVR$Estimate[88]` [95%CI: `r mods_SMD_logCVR$Lower[88]` to `r mods_SMD_logCVR$Upper[88]`]; $I^2_{study}$ = `r mods_SMD_logCVR$I2.study[88]`, $I^2_{group}$ = `r mods_SMD_logCVR$I2.group[88]`).

There is however a potential limitation for the $\textrm{ln}CVR$ also that may need to be considered. Firstly, it is limited to the use of ratio scale data (which is not the case for the $\textrm{ln}\hat\sigma$ or $\textrm{ln}VR$). But secondly, whilst the $\textrm{ln}CVR$ is useful in situations where there is a mean-variance relationship the use of the $CV$ in the effect size statistic assumes proportionality between standard deviation and mean. Where we see the kind of heteroskedasticity in the relationship between mean and standard deviation as we do for the change scores here (figure \@ref(fig:mean-variance-delta-plot)) an alternative approach that is equivalent may be more appropriate. 

The multilevel mixed-effects meta-analysis model using $\textrm{ln}CVR$ as used above can be written as follows:

\begin{equation}
\textrm{ln}CVR_{ij}=\mu+\tau_{i}+\tau_{j}+m_{ij} 
(\#eq:lnCVR-model-eq)
\end{equation}

where $\textrm{ln}CVR_{ij}$ is each effect size, as in equation \@ref(eq:lnCVR-eq), for the $j\textrm{th}$ group ($j = 1,2,\cdots,N_{j}$; where $N_{j}$ is the number of groups) in the $i\textrm{th}$ study ($i = 1,2,\cdots,N_{i}$; where $N_{i}$ is the number of studies), $\mu$ is the intercept or overall mean, $\tau_{i}$ is the deviation from $\mu$ for the $i\textrm{th}$ study and $\tau_{j}$ is the deviation for the $j\textrm{th}$ group, which are assumed to be normall distributed around zero with variance of $\sigma^2_{\tau}$, and $m_{ij}$ is the sampling error for each effect size normally distributed with $\sigma^2_{\textrm{ln}CVR_{ij}}$. Instead, we can use a version of the random slope model described above (equation \@ref(eq:lnm-lns-model-eq) and following paragraph) to compare the variability between intervention and control groups using $\textrm{ln}\hat\sigma$ and $\textrm{ln}\overline{x}$. In this case, the categorical variable for the outcome type is instead swapped for the group and the new model term included becomes $(\beta_{2} + \varphi_{i} + \varphi_{j})Group$ with $Group$ as a dummy coded variable for the group (i.e., non-training control = 0, and RT intervention = 1), where $\beta_{2}$ is the slope or regression coefficient for $Group$, and $\varphi_{i}$ is the deviation (random slope) from $\beta_{2}$ for the $i\textrm{th}$ study and $\varphi_{j}$ is the deviation for the $j\textrm{th}$ group. 

```{r, message=FALSE,warning=FALSE,echo=FALSE}
# load the summary dataframes to the environment
load(here("models/RobuEstMultiLevelModel_log_mean_mod_strength"))
load(here("models/RobuEstMultiLevelModel_log_mean_mod_hypertrophy"))

```

Given the heteroskedasticity in the change scores means and standard deviations (see figure \@ref(fig:mean-variance-delta-plot)) we fit this model to the dataset. The results were however largely similar to those found using the $\textrm{ln}CVR$ model for strength ($\beta_{\textrm{ln}\hat\sigma[Group \textrm{ for RT}]}$ = `r round(RobuEstMultiLevelModel_log_mean_mod_strength$b[3],2)` [95%CI: `r round(RobuEstMultiLevelModel_log_mean_mod_strength$ci.lb[3],2)` to `r round(RobuEstMultiLevelModel_log_mean_mod_strength$ci.ub[3],2)`]) and hypertrophy ($\beta_{\textrm{ln}\hat\sigma[Group \textrm{ for RT}]}$ = `r round(RobuEstMultiLevelModel_log_mean_mod_hypertrophy$b[3],2)` [95%CI: `r round(RobuEstMultiLevelModel_log_mean_mod_hypertrophy$ci.lb[3],2)` to `r round(RobuEstMultiLevelModel_log_mean_mod_hypertrophy$ci.ub[3],2)`]). See figure \@ref(fig:model-mean-variance-delta-plot).

```{r model-mean-variance-delta-plot, message=FALSE, warning=FALSE, echo=FALSE,fig.height=4, fig.width=8, fig.cap="Meta-analytic scatter plot of the log mean and log standard deviation of change scores"}

# "Meta-analytic scatter plot of the log mean and log standard deviation of change scores. Note, fitted lines are the regression slopes for control group (CON) and resistance training intervention (RT) groups each with their 95% confidence interval band."

load(here("plots/model_mean_variance_delta_plots"))

model_mean_variance_delta_plots

```

The reason for this apparent reduction in variation after introduction of an RT intervention is not necessarily discernible from this analysis. Perhaps the introduction of an RT intervention has indirect effects that reduce other sources of random variance (e.g., diet, other physical activity etc.; [@halliday_resistance_2017]), or a ceiling effect on change (i.e., plateau in response; [@steele_long-term_2022]) has a constraining effect [@cortes_martinez_constant_2021]. Hopefully it is clear from the regression model here where we have included both fixed and random predictors as both categorical (i.e., $Outcome$, or $Group$) and continuous (i.e., $\textrm{ln}\overline{x}$) that there is considerable flexibility in the inclusion of predictors (i.e., meta-regression) when exploring variance through a meta-analytic framework. Models can be fit to explore not only how study and group level characteristics moderate effect size estimates when considering not only SMDs, but also when considering the variance based effect size statistics and models employed in this article[^8]. 

# Discussion
Given the apparent lack of awareness of the utility of meta-analytic frameworks for exploring variance, and the potential value such analyses can offer for the sport and exercise sciences, we have presented some existing effect size statistics and models pertinent to this that hopefully will encourage and support researchers in the field to embrace more than just the mean when engaging in quantitative evidence synthesis. Indeed, for a field such as sport and exercise science where samples sizes are typically small, meta-analysis becomes even more valuable as such small sample in primary studies have even lower statistical power to detect differences in variation as compared to means [@yang_low_2022]. The examples we presented used data from RT studies included in a recent meta-analysis published in the *Journal of Sport Sciences* [@polito_moderators_2021], and so hopefully are more relatable for researchers in sport and exercise sciences. 

Given the considerable interest in *precision* or *personalised* exercise prescription in particular, it is of particular interest to note the different conclusions drawn dependent upon the approach taken to determining from non-training control and RT intervention data whether or not there is *detectable* inter-individual response variation present. Using absolute comparisons of variance such as $SD_{ir}$ and $\textrm{ln}VR$ gave the impression that the introduction of the RT intervention likely increased variance above random error, suggesting the presence of inter-individual response variation. In the case of RT interventions there is evidently an average intervention effect which is positive and as such this result might merely imply that while all likely benefit, some benefit much moreso than others. Exploring variation however even in the absence of average intervention effects might still be important as those with large enough variance could imply that the intervention is at least beneficial to some [@usui_meta-analysis_2021]. Such results might lead researchers to consider that further research exploring subgroup- or participant-by-intervention interactions is required to maximise successful practical application of RT interventions to maximise strength and hypertrophy outcomes from our example.

However, much like that seen in cross-sectional pre-intervention scores here and most physical and biological systems, change scores demonstrated a mean-variance relationship in addition to heteroskedasticity. The likely more appropriate analyses in this case using the $\textrm{ln}CVR$ in addition to the random slope model of $\textrm{ln}\hat\sigma$ revealed conclusions in the opposite direction of the absolute variance comparisons; essentially, that the introduction of the RT intervention may have slightly *decreased* change score variance implying that there is likely little to no inter-individual response variation to explain. Interventions, such as RT interventions explored here, which induce both meaningful SMDs and also show little evidence suggestive of interindividual variation are likely to be widely generalisable and so from a practical perspective might offer considerable value in that we can have high expectations that everyone receiving them will likely improve [@usui_meta-analysis_2021]; that is to say we can assume a constant effect and that the average intervention effect is indicative of the individual intervention effect [@cortes_martinez_constant_2021]. Interventions such as these are valuable for the simplification of guidelines and recommendations. For example, muscle strengthening interventions such as RT are recommended for *everyone* in current physical activity guidelines and in such applications there is likely value in a simple approach to recommendations [@steele_higher_2017; @steele_long-term_2022]. 

# Conclusion
Embracing variability and focusing on more than merely the mean differences between groups or conditions, such as intervention and control comparisons, has the potential to inform experimental design and lead to changes in both the approach and direction of follow-up studies. Where considerable differences in variation are present, this suggests a meaningful line of research should be aimed at identifying subgroup- or participant-by-intervention interactions. Where variance differences are limited this suggests that translational work towards generalisable implementation might be most meaningful. Future meta-analyses in the field of sport and exercise science should consider the value of concomitantly exploring means and variances utlising the established approaches [@nakagawa_meta-analysis_2015; @hopkins_individual_2015; @atkinson_true_2015; @atkinson_issues_2019; @usui_meta-analysis_2021; @mills_detecting_2021] presented here and echoing the efforts of other recent work [@kelley_are_2022; @kelley_are_2020; @esteves_individual_2021; @bonafiglia_interindividual_2022; @steele_slow_2021; @fisher_role_2022]. 

# References

<div id="refs"></div>

[^1]: Though notably not all meta-analyses use *magnitude based* effect sizes. Indeed some explicitly use what Caldwell and Vigotsky term *signal-to-noise* effect sizes (e.g., @heidel_machines_2022).

[^2]: We will refer to both merely as the SMD throughout the manuscript for simplicity.

[^3]: Exploration of methodological approaches and their impact on heterogeneity have also been explored in preclinical research [@usui_meta-analysis_2021].

[^4]: For one clear example, see figure 1A in Vigostky et al. [-@vigotsky_improbable_2020] who show that the mean and standard deviation for baseline strength values typically scale with one another across most studies.

[^5]: The authors of the meta-analysis did not make their extracted data openly available, not respond to our request for the extracted data. Further, their original analysis included 119 studies however we were unable to extract data for our analyses from 8 of these for a variety of reasons (e.g., only percentage change data was reported, no standard deviations for control groups reported).

[^6]: Data was coded such that study and group had explicit nesting.

[^7]: Note, we also explored for signs of small study bias, including publication bias favouring the finding of intervention effects, for the SMDs given that the relative lack of awareness for variance based effect sizes in the field implies that they might have more influence over such biases. There did not appear to be any obvious small study bias in the dataset (ADD LINK TO SUPPLEMENTARY)  

[^8]: See supplementary materials (ADD LINK TO SUPPLEMENTARY) for model estimates for both SMD and $\textrm{ln}CVR$ (used as results for $\textrm{ln}CVR$ and the random slope model were similar) across a range of categorical and continous predictors for both strength and hypertrophy outcomes. There were no obvious moderators of $\textrm{ln}CVR$ in particular. 